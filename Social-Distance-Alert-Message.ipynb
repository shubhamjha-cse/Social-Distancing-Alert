{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Distancing Alert using Artificial Intelligence\n",
    "\n",
    "An Artifical Intellegence model on python program desinged using Deep Neural Network and Computer Vision which gives alert warnings when people violates social distancing.  \n",
    "\n",
    "![](resources/social_distancing2.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About \n",
    "\n",
    "**Abstract :** While it may be disappointing to hear that so many sports events, cruises, festivals and other gatherings are being cancelled, there is a public health reason for these measures. These cancellations help stop or slow down the spread of disease allowing the health care system to more readily care for patients over time.\n",
    "\n",
    "Cancelling events that are likely to draw crowds is an example of social and physical distancing. Social distancing is deliberately increasing the physical space between people to avoid spreading illness. Staying at least six feet away from other people lessens your chances of catching COVID-19. Wear a cloth face covering where social distancing canâ€™t be practiced, especially in areas of significant community-based transmission.\n",
    "\n",
    "Other examples of social and physical distancing that allow you to avoid larger crowds or crowded spaces are:\n",
    "* Working from home instead of at the office\n",
    "* Closing schools or switching to online classes\n",
    "* Visiting loved ones by electronic devices instead of in person\n",
    "* Cancelling or postponing conferences and large meetings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Developer :**  \n",
    "Shubham Manikant Jha  \n",
    "shubhamjha.cse@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Distancing Alert using artificial Intelligence\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Packages\n",
    "\n",
    "* ```numpy``` : Library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.  \n",
    "* ```time``` : Python module that provides time related operations\n",
    "* ```cv2``` : OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library, built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products.\n",
    "* ```playsound``` : Pure Python, cross platform, single function module with no dependencies for playing sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import math\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsPath = \"coco.names.txt\"\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),\n",
    "\tdtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsPath = r\"C:\\Users\\Shubham Jha\\Desktop\\Social\\yolov3.weights\"\n",
    "configPath =  r\"C:\\Users\\Shubham Jha\\Desktop\\Social\\yolov3.cfg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "p = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Prediction Time : 3.793591 seconds\n",
      "Frame Prediction Time : 1.908385 seconds\n",
      "Frame Prediction Time : 1.629854 seconds\n",
      "Frame Prediction Time : 1.867941 seconds\n",
      "Frame Prediction Time : 1.429752 seconds\n",
      "Frame Prediction Time : 1.581778 seconds\n",
      "Frame Prediction Time : 1.424261 seconds\n",
      "Frame Prediction Time : 1.438875 seconds\n",
      "Frame Prediction Time : 1.400510 seconds\n",
      "Frame Prediction Time : 1.427359 seconds\n",
      "Frame Prediction Time : 1.415817 seconds\n",
      "Frame Prediction Time : 1.474849 seconds\n",
      "Frame Prediction Time : 1.385562 seconds\n",
      "Frame Prediction Time : 1.372183 seconds\n",
      "Frame Prediction Time : 1.364232 seconds\n",
      "Frame Prediction Time : 1.433969 seconds\n",
      "Frame Prediction Time : 1.425446 seconds\n",
      "Frame Prediction Time : 1.406273 seconds\n",
      "Frame Prediction Time : 1.566837 seconds\n",
      "Frame Prediction Time : 1.737977 seconds\n",
      "Frame Prediction Time : 1.783367 seconds\n",
      "Frame Prediction Time : 1.483333 seconds\n",
      "Frame Prediction Time : 1.498151 seconds\n",
      "Frame Prediction Time : 1.531464 seconds\n",
      "Frame Prediction Time : 1.523201 seconds\n",
      "Frame Prediction Time : 1.680552 seconds\n",
      "Frame Prediction Time : 1.528246 seconds\n",
      "Frame Prediction Time : 1.580192 seconds\n",
      "Frame Prediction Time : 1.631549 seconds\n"
     ]
    }
   ],
   "source": [
    "while(cap.isOpened()):\n",
    "    \n",
    "    ret,image=cap.read()\n",
    "    \n",
    "        \n",
    "    (H, W) = image.shape[:2]\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    start = time.time()\n",
    "    layerOutputs = net.forward(ln)\n",
    "    end = time.time()\n",
    "    print(\"Frame Prediction Time : {:.6f} seconds\".format(end - start))\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > 0.1 and classID == 0:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "                \n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5,0.3)\n",
    "    ind = []\n",
    "    for i in range(0,len(classIDs)):\n",
    "        if(classIDs[i]==0):\n",
    "            ind.append(i)\n",
    "    a = []\n",
    "    b = []\n",
    "\n",
    "    if len(idxs) > 0:\n",
    "            for i in idxs.flatten():\n",
    "                (x, y) = (boxes[i][0], boxes[i][1])\n",
    "                (w, h) = (boxes[i][2], boxes[i][3])\n",
    "                a.append(x)\n",
    "                b.append(y)\n",
    "                \n",
    "    distance=[] \n",
    "    nsd = []\n",
    "    for i in range(0,len(a)-1):\n",
    "        for k in range(1,len(a)):\n",
    "            if(k==i):\n",
    "                break\n",
    "            else:\n",
    "                x_dist = (a[k] - a[i])\n",
    "                y_dist = (b[k] - b[i])\n",
    "                d = math.sqrt(x_dist * x_dist + y_dist * y_dist)\n",
    "                distance.append(d)\n",
    "                if(d <=100):\n",
    "                    nsd.append(i)\n",
    "                    nsd.append(k)\n",
    "                nsd = list(dict.fromkeys(nsd))\n",
    "                print(nsd)\n",
    "    color = (0, 0, 255) \n",
    "    for i in nsd:\n",
    "        (x, y) = (boxes[i][0], boxes[i][1])\n",
    "        (w, h) = (boxes[i][2], boxes[i][3])\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "        text = \"Alert\"\n",
    "        playsound('alert.wav')\n",
    "        cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 2)\n",
    "        p = 99\n",
    "    color = (0, 255, 0) \n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            if (i in nsd):\n",
    "                break\n",
    "            else:\n",
    "                (x, y) = (boxes[i][0], boxes[i][1])\n",
    "                (w, h) = (boxes[i][2], boxes[i][3])\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "                text = 'OK'\n",
    "                cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 2)   \n",
    "    \n",
    "    cv2.imshow(\"Social Distancing Detector\", image)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
